{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "bVnbbVTUCjbi",
        "outputId": "87bd2782-e984-43a6-81a1-43468679c24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7a6f7a5901652c65e1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7a6f7a5901652c65e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# PDF Q&A Chatbot with Gradio UI in One Notebook\n",
        "\n",
        "# STEP 1: Install Required Packages\n",
        "!pip install openai langchain langchain-community faiss-cpu gradio PyPDF2 tiktoken --quiet\n",
        "\n",
        "# STEP 2: Import Libraries\n",
        "import os\n",
        "import PyPDF2\n",
        "import gradio as gr\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# STEP 3: Set Your OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"  # Replace with your OpenAI key\n",
        "\n",
        "# STEP 4: Helper Function to Extract Text from PDF (in-memory)\n",
        "def extract_text_from_pdf(file_obj):\n",
        "    reader = PyPDF2.PdfReader(file_obj)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text\n",
        "    return text\n",
        "\n",
        "# STEP 5: Build Vector Index\n",
        "def create_vector_index(pdf_text):\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(pdf_text)\n",
        "    docs = [Document(page_content=chunk) for chunk in chunks]\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# STEP 6: Global Objects (state)\n",
        "vector_index = None\n",
        "qa_chain = None\n",
        "\n",
        "# STEP 7: Upload Handler (with error handling)\n",
        "def process_pdf(file_path):\n",
        "    global vector_index, qa_chain\n",
        "    try:\n",
        "        if file_path is None:\n",
        "            return \"No file uploaded.\"\n",
        "\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            pdf_text = extract_text_from_pdf(f)\n",
        "\n",
        "        if not pdf_text.strip():\n",
        "            return \"No extractable text found in PDF.\"\n",
        "\n",
        "        print(\"First 500 characters of extracted text:\", pdf_text[:500])  # Debug info\n",
        "\n",
        "        vector_index = create_vector_index(pdf_text)\n",
        "        llm = ChatOpenAI(temperature=0)\n",
        "        qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vector_index.as_retriever())\n",
        "        return \"PDF processed successfully! You can now ask questions.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# STEP 8: Q&A Function\n",
        "def ask_question(question):\n",
        "    if not qa_chain:\n",
        "        return \"Please upload a PDF first.\"\n",
        "    return qa_chain.run(question)\n",
        "\n",
        "# STEP 9: Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## PDF Q&A Chatbot\\nUpload a PDF and ask questions about its content.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        pdf_input = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"], type=\"filepath\")\n",
        "        upload_output = gr.Textbox(label=\"Upload Status\")\n",
        "\n",
        "    pdf_input.change(fn=process_pdf, inputs=[pdf_input], outputs=[upload_output])\n",
        "\n",
        "    question = gr.Textbox(label=\"Enter your question\")\n",
        "    answer = gr.Textbox(label=\"Answer\")\n",
        "\n",
        "    ask_btn = gr.Button(\"Ask\")\n",
        "    ask_btn.click(fn=ask_question, inputs=[question], outputs=[answer])\n",
        "\n",
        "# STEP 10: Launch Interface\n",
        "demo.launch(debug=False)"
      ]
    }
  ]
}